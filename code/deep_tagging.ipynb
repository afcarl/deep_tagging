{
 "metadata": {
  "name": "",
  "signature": "sha256:f77d3718946fc6196c15fb4493c7e30f303f45c3ff76e9df8dbe034324d9dc3f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import os\n",
      "os.environ['THEANO_FLAGS']='floatX=float32,device=gpu,nvcc.fastmath=True'\n",
      "\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "tf = theano.config.floatX\n",
      "\n",
      "from math import sqrt\n",
      "from scipy import io\n",
      "from sklearn.metrics import roc_auc_score, average_precision_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GeForce GRID K520\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Load data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "K = 1024"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DATA_DIR = '/dataeast/dawen/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = np.load(os.path.join(DATA_DIR, 'X_train_K%d.npy' % K))\n",
      "X_test = np.load(os.path.join(DATA_DIR, 'X_test_K%d.npy' % K))\n",
      "y_train = np.load(os.path.join(DATA_DIR, 'y_train.npy'))\n",
      "y_test = np.load(os.path.join(DATA_DIR, 'y_test.npy'))\n",
      "\n",
      "y_train[y_train == 0] = -1\n",
      "y_test[y_test == 0] = -1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#X_train = X_train / np.sum(X_train, axis=1, keepdims=True).astype(tf)\n",
      "#X_test = X_test / np.sum(X_test, axis=1, keepdims=True).astype(tf)\n",
      "\n",
      "# for numpy 1.6\n",
      "X_train = X_train / (np.sum(X_train, axis=1)[:, None]).astype(tf)\n",
      "X_test = X_test / (np.sum(X_test, axis=1)[:, None]).astype(tf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Define the network"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rng = np.random.RandomState(seed=98765)\n",
      "\n",
      "rng_CUDA = theano.sandbox.cuda.rng_curand.CURAND_RandomStreams(98765)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples, n_feats = X_train.shape\n",
      "n_tags = y_train.shape[1]\n",
      "\n",
      "batch_size = 100\n",
      "\n",
      "X_batch = theano.shared(np.zeros((batch_size, n_feats), dtype=tf), 'X_batch', borrow=True)\n",
      "y_batch = theano.shared(np.zeros((batch_size, n_tags), dtype=np.int32), 'y_batch', borrow=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticRegressionLayer:\n",
      "    def __init__(self, rng, input, n_in, n_out):\n",
      "        # input and params\n",
      "        self.input = input\n",
      "        \n",
      "        self.W = theano.shared(0.01 * rng.randn(n_in, n_out).astype(tf), name='W', borrow=True)\n",
      "        self.b = theano.shared(0.01 * rng.randn(n_out).astype(tf), name='b', borrow=True)\n",
      "        \n",
      "        self.params = [self.W, self.b]\n",
      "\n",
      "        # AdaGrad \n",
      "        self.hist_grad_W = theano.shared(np.zeros((n_in, n_out), dtype=tf), name='hist_grad_W', borrow=True)\n",
      "        self.hist_grad_b = theano.shared(np.zeros(n_out, dtype=tf), name='hist_grad_b', borrow=True)\n",
      "        \n",
      "        self.hist_grads = [self.hist_grad_W, self.hist_grad_b]\n",
      "        \n",
      "        # output\n",
      "        self.linout = T.dot(self.input, self.W) + self.b\n",
      "        \n",
      "        self.L2_sq = T.sum(T.sqr(self.W)) + T.sum(T.sqr(self.b))  \n",
      "        \n",
      "    def neg_log_likeli(self, y):\n",
      "        return T.mean(T.nnet.softplus(T.neg(y * self.linout)))\n",
      "           \n",
      "        \n",
      "class HiddenReluLayer(object):\n",
      "    def __init__(self, rng, rng_CUDA, input, n_in, n_out, dropout):\n",
      "        # input and params\n",
      "        self.input = input\n",
      "        self.dropout = dropout\n",
      "        \n",
      "        self.W = theano.shared(value=0.01 * rng.randn(n_in, n_out).astype(tf), name='W', borrow=True)\n",
      "        self.b = theano.shared(value=0.01 * rng.randn(n_out).astype(tf), name='b', borrow=True)\n",
      "        \n",
      "        self.params = [self.W, self.b]\n",
      "        \n",
      "        # AdaGrad\n",
      "        self.hist_grad_W = theano.shared(np.zeros((n_in, n_out), dtype=tf), name='hist_grad_W', borrow=True)\n",
      "        self.hist_grad_b = theano.shared(np.zeros(n_out, dtype=tf), name='hist_grad_b', borrow=True)\n",
      "        \n",
      "        self.hist_grads = [self.hist_grad_W, self.hist_grad_b]\n",
      "        \n",
      "        # output\n",
      "        lin_out = T.dot(self.input, self.W) + self.b\n",
      "        if T.gt(self.dropout, 0):\n",
      "            mask = 1.0 / (1.0 - self.dropout) * T.cast(rng_CUDA.uniform(size=(n_out, )) > self.dropout, dtype=tf)\n",
      "            lin_out = lin_out * mask\n",
      "        self.output = T.maximum(lin_out, 0)\n",
      "        self.L2_sq = T.sum(T.sqr(self.W)) + T.sum(T.sqr(self.b))\n",
      "        \n",
      "    def activation(self, X):\n",
      "        output = T.maximum(T.dot(X, self.W) + self.b, 0)\n",
      "        return output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_units = 1200\n",
      "\n",
      "lam = T.scalar(name='lambda')\n",
      "delta = T.scalar(name='delta')\n",
      "\n",
      "layer0 = HiddenReluLayer(rng, rng_CUDA, input=X_batch, n_in=n_feats, n_out=n_units, dropout=delta)\n",
      "\n",
      "layer1 = HiddenReluLayer(rng, rng_CUDA, input=layer0.output, n_in=n_units, n_out=n_units, dropout=delta)\n",
      "\n",
      "layer2 = HiddenReluLayer(rng, rng_CUDA, input=layer1.output, n_in=n_units, n_out=n_units, dropout=delta)\n",
      "\n",
      "layer3 = LogisticRegressionLayer(rng, input=layer2.output, n_in=n_units, n_out=n_tags)\n",
      "\n",
      "layers = [layer0, layer1, layer2, layer3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = []\n",
      "hist_grads = []\n",
      "\n",
      "for layer in layers:\n",
      "    params += layer.params\n",
      "    hist_grads += layer.hist_grads"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cost = layers[-1].neg_log_likeli(y_batch)\n",
      "\n",
      "for layer in layers:\n",
      "    cost = cost + lam * layer.L2_sq\n",
      "\n",
      "grads = T.grad(cost, params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eta = T.scalar(name='eta')\n",
      "  \n",
      "eps = 1e-8\n",
      "\n",
      "updates = []\n",
      "\n",
      "for param_i, grad_i, hist_grad_i in zip(params, grads, hist_grads):\n",
      "    new_hist_grad_i = hist_grad_i + T.sqr(grad_i)\n",
      "    updates.append((hist_grad_i, new_hist_grad_i))\n",
      "    updates.append((param_i, param_i - eta / (eps + T.sqrt(new_hist_grad_i)) * grad_i))\n",
      "    \n",
      "update_f = theano.function(inputs=[eta, lam, delta], outputs=[layers[-1].linout, cost], updates=updates)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _predict(X, y):\n",
      "    cost = 0\n",
      "    h = X\n",
      "    for layer in layers[:-1]:\n",
      "        h = h.dot(layer.W.get_value()) + layer.b.get_value()\n",
      "        h = np.maximum(h, 0)\n",
      "        cost += lam * (np.sum(layer.W.get_value()**2) + np.sum(layer.b.get_value()**2))\n",
      "    h = h.dot(layers[-1].W.get_value()) + layers[-1].b.get_value()\n",
      "    cost += np.mean(np.log(1 + np.exp(-y * h)))\n",
      "    return h, cost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cost_train = []\n",
      "cost_test = []\n",
      "acc_train = []\n",
      "acc_test = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eta = .05\n",
      "lam = 0\n",
      "delta = 0.25"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nepochs = 50\n",
      "print 'epoch\\tcost.train\\tcost.test\\ttrain.acc\\ttest.acc'\n",
      "sys.stdout.flush()\n",
      "\n",
      "for epoch in xrange(nepochs):\n",
      "    cost_batch = []\n",
      "    acc_batch = []\n",
      "    # Execute stochastic gradient updates\n",
      "    for i in xrange(0, n_samples, batch_size):\n",
      "        inds = np.arange(i, min(i + batch_size, n_samples), dtype=int)\n",
      "        X_batch.set_value(X_train[inds].astype(tf))\n",
      "        y_batch.set_value(y_train[inds].astype(np.int32))\n",
      "\n",
      "        pred, cost = update_f(eta, lam, delta)\n",
      "        cost_batch.append(cost)\n",
      "        acc_batch.append(1 - np.mean(np.logical_xor(pred > 0, y_train[inds] > 0)))\n",
      "\n",
      "    cost_train.append(np.mean(cost_batch))\n",
      "    acc_train.append(np.mean(acc_batch))\n",
      "    \n",
      "    pred_test, cost = _predict(X_test, y_test)\n",
      "    cost_test.append(cost)\n",
      "    acc_test.append(1 - np.mean(np.logical_xor(pred_test > 0, y_test > 0)))\n",
      "    \n",
      "    pred_test = 1. / (1 + np.exp(-pred_test))\n",
      "            \n",
      "    print('%d\\t%.3e\\t%.3e\\t%.3e\\t%.3e' % (epoch, cost_train[-1], cost_test[-1], acc_train[-1], acc_test[-1]))\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch\tcost.train\tcost.test\ttrain.acc\ttest.acc\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\t4.196e-02\t1.654e-01\t9.890e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\t4.189e-02\t1.663e-01\t9.890e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\t4.180e-02\t1.668e-01\t9.890e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\t4.176e-02\t1.658e-01\t9.890e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\t4.167e-02\t1.669e-01\t9.890e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5\t4.162e-02\t1.677e-01\t9.890e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6\t4.160e-02\t1.673e-01\t9.890e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7\t4.158e-02\t1.672e-01\t9.890e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8\t4.149e-02\t1.670e-01\t9.890e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9\t4.145e-02\t1.680e-01\t9.890e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10\t4.142e-02\t1.684e-01\t9.890e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11\t4.137e-02\t1.696e-01\t9.890e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12\t4.132e-02\t1.669e-01\t9.890e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13\t4.132e-02\t1.713e-01\t9.890e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14\t4.126e-02\t1.693e-01\t9.890e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15\t4.116e-02\t1.694e-01\t9.890e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "16\t4.117e-02\t1.692e-01\t9.890e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "17\t4.113e-02\t1.701e-01\t9.891e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "18\t4.110e-02\t1.702e-01\t9.890e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "19\t4.103e-02\t1.690e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20\t4.102e-02\t1.711e-01\t9.891e-01\t9.550e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "21\t4.102e-02\t1.691e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "22\t4.093e-02\t1.694e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "23\t4.092e-02\t1.687e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "24\t4.089e-02\t1.690e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "25\t4.087e-02\t1.702e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "26\t4.077e-02\t1.691e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "27\t4.075e-02\t1.702e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "28\t4.074e-02\t1.700e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "29\t4.073e-02\t1.702e-01\t9.891e-01\t9.552e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "30\t4.073e-02\t1.699e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "31\t4.065e-02\t1.694e-01\t9.891e-01\t9.552e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "32\t4.061e-02\t1.697e-01\t9.891e-01\t9.552e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "33\t4.056e-02\t1.699e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "34\t4.055e-02\t1.709e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "35\t4.058e-02\t1.720e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "36\t4.052e-02\t1.718e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "37\t4.050e-02\t1.705e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "38\t4.047e-02\t1.688e-01\t9.891e-01\t9.552e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "39\t4.045e-02\t1.703e-01\t9.891e-01\t9.552e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "40\t4.042e-02\t1.728e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "41\t4.037e-02\t1.721e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "42\t4.039e-02\t1.723e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "43\t4.034e-02\t1.718e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "44\t4.028e-02\t1.719e-01\t9.891e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "45\t4.029e-02\t1.706e-01\t9.891e-01\t9.552e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "46\t4.023e-02\t1.727e-01\t9.892e-01\t9.551e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "47\t4.024e-02\t1.702e-01\t9.892e-01\t9.552e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "48\t4.018e-02\t1.718e-01\t9.892e-01\t9.552e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "49\t4.020e-02\t1.709e-01\t9.892e-01\t9.552e-01\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(acc_train)\n",
      "plt.plot(acc_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "[<matplotlib.lines.Line2D at 0xab95f10>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD9CAYAAABTJWtQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0xab8a190>"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute evaluation metrics\n",
      "def construct_pred_mask(tags_predicted, predictat):\n",
      "    n_samples, n_tags = tags_predicted.shape\n",
      "    rankings = np.argsort(-tags_predicted, axis=1)[:, :predictat]\n",
      "    tags_predicted_binary = np.zeros_like(tags_predicted, dtype=bool)\n",
      "    for i in xrange(n_samples):\n",
      "        tags_predicted_binary[i, rankings[i]] = 1\n",
      "    return tags_predicted_binary\n",
      "\n",
      "def per_tag_prec_recall(tags_predicted_binary, tags_true_binary):\n",
      "    mask = np.logical_and(tags_predicted_binary, tags_true_binary)\n",
      "    prec = mask.sum(axis=0) / (tags_predicted_binary.sum(axis=0) + np.spacing(1))\n",
      "    tags_true_count = tags_true_binary.sum(axis=0).astype(float)\n",
      "    idx = (tags_true_count > 0)\n",
      "    recall = mask.sum(axis=0)[idx] / tags_true_count[idx]\n",
      "    return prec, recall\n",
      "\n",
      "\n",
      "def aroc_ap(tags_true_binary, tags_predicted):\n",
      "    n_tags = tags_true_binary.shape[1]\n",
      "    \n",
      "    auc = list()\n",
      "    aprec = list()\n",
      "    for i in xrange(n_tags):\n",
      "        if np.sum(tags_true_binary[:, i]) != 0:\n",
      "            auc.append(roc_auc_score(tags_true_binary[:, i], tags_predicted[:, i]))\n",
      "            aprec.append(average_precision_score(tags_true_binary[:, i], tags_predicted[:, i]))\n",
      "    return auc, aprec\n",
      "\n",
      "\n",
      "def print_out_metrics(tags_true_binary, tags_predicted, predictat):\n",
      "    tags_predicted_binary = construct_pred_mask(tags_predicted, predictat)\n",
      "    prec, recall = per_tag_prec_recall(tags_predicted_binary, tags_true_binary)\n",
      "    mprec, mrecall = np.mean(prec), np.mean(recall)\n",
      "    \n",
      "    print 'Precision = %.3f (%.3f)' % (mprec, np.std(prec) / sqrt(prec.size))\n",
      "    print 'Recall = %.3f (%.3f)' % (mrecall, np.std(recall) / sqrt(recall.size))\n",
      "    print 'F-score = %.3f' % (2 * mprec * mrecall / (mprec + mrecall))\n",
      "\n",
      "    auc, aprec = aroc_ap(tags_true_binary, tags_predicted)\n",
      "    print 'AROC = %.3f (%.3f)' % (np.mean(auc), np.std(auc) / sqrt(len(auc)))\n",
      "    print 'AP = %.3f (%.3f)' % (np.mean(aprec), np.std(aprec) / sqrt(len(aprec)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tags_predicted = pred_test\n",
      "print tags_predicted.min(), tags_predicted.max()\n",
      "\n",
      "div_factor = 1.25\n",
      "tags_predicted = tags_predicted - div_factor * np.mean(tags_predicted, axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7.20792e-14 0.911772\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# results with dropout = 0.5 (50 epochs)\n",
      "predictat = 20\n",
      "tags_true_binary = (y_test > 0)\n",
      "\n",
      "print_out_metrics(tags_true_binary, tags_predicted, predictat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Precision = 0.184 (0.009)\n",
        "Recall = 0.207 (0.009)\n",
        "F-score = 0.195\n",
        "AROC = 0.781 (0.005)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "AP = 0.178 (0.007)\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# results with dropout = 0.25 (50 epochs)\n",
      "predictat = 20\n",
      "tags_true_binary = (y_test > 0)\n",
      "\n",
      "print_out_metrics(tags_true_binary, tags_predicted, predictat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Precision = 0.192 (0.009)\n",
        "Recall = 0.212 (0.009)\n",
        "F-score = 0.202\n",
        "AROC = 0.777 (0.005)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "AP = 0.177 (0.007)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# results with dropout = 0.25 (100 epochs)\n",
      "predictat = 20\n",
      "tags_true_binary = (y_test > 0)\n",
      "\n",
      "print_out_metrics(tags_true_binary, tags_predicted, predictat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Precision = 0.193 (0.008)\n",
        "Recall = 0.215 (0.009)\n",
        "F-score = 0.203\n",
        "AROC = 0.775 (0.005)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "AP = 0.172 (0.007)\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}