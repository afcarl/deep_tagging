{
 "metadata": {
  "name": "",
  "signature": "sha256:71a67d1012ab49c3a621cccdc8f32d6475d070bce896ff248c752071588cca2a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import os\n",
      "os.environ['THEANO_FLAGS']='floatX=float32,device=gpu,nvcc.fastmath=True'\n",
      "\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "tf = theano.config.floatX\n",
      "\n",
      "from math import sqrt\n",
      "from scipy import io\n",
      "from sklearn.metrics import roc_auc_score, average_precision_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GeForce GRID K520\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Load data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "K = 1024"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DATA_DIR = '/dataeast/dawen/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = np.load(os.path.join(DATA_DIR, 'X_train_K%d.npy' % K))\n",
      "X_test = np.load(os.path.join(DATA_DIR, 'X_test_K%d.npy' % K))\n",
      "y_train = np.load(os.path.join(DATA_DIR, 'y_train.npy'))\n",
      "y_test = np.load(os.path.join(DATA_DIR, 'y_test.npy'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#X_train = X_train / np.sum(X_train, axis=1, keepdims=True).astype(tf)\n",
      "#X_test = X_test / np.sum(X_test, axis=1, keepdims=True).astype(tf)\n",
      "\n",
      "# for numpy 1.6\n",
      "X_train = X_train / (np.sum(X_train, axis=1)[:, None]).astype(tf)\n",
      "X_test = X_test / (np.sum(X_test, axis=1)[:, None]).astype(tf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Define the network"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rng = np.random.RandomState(seed=98765)\n",
      "\n",
      "rng_CUDA = theano.sandbox.cuda.rng_curand.CURAND_RandomStreams(98765)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples, n_feats = X_train.shape\n",
      "n_tags = y_train.shape[1]\n",
      "\n",
      "batch_size = 100\n",
      "\n",
      "X_batch = theano.shared(np.zeros((batch_size, n_feats), dtype=tf), 'X_batch', borrow=True)\n",
      "y_batch = theano.shared(np.zeros((batch_size, n_tags), dtype=np.int32), 'y_batch', borrow=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticRegressionLayer:\n",
      "    def __init__(self, rng, input, n_in, n_out):\n",
      "        # input and params\n",
      "        self.input = input\n",
      "        \n",
      "        self.W = theano.shared(0.01 * rng.randn(n_in, n_out).astype(tf), name='W', borrow=True)\n",
      "        self.b = theano.shared(0.01 * rng.randn(n_out).astype(tf), name='b', borrow=True)\n",
      "        \n",
      "        self.params = [self.W, self.b]\n",
      "\n",
      "        # AdaGrad \n",
      "        self.hist_grad_W = theano.shared(np.zeros((n_in, n_out), dtype=tf), name='hist_grad_W', borrow=True)\n",
      "        self.hist_grad_b = theano.shared(np.zeros(n_out, dtype=tf), name='hist_grad_b', borrow=True)\n",
      "        \n",
      "        self.hist_grads = [self.hist_grad_W, self.hist_grad_b]\n",
      "        \n",
      "        # output\n",
      "        self.output = T.nnet.softmax(T.dot(self.input, self.W) + self.b)\n",
      "        self.L2_sq = T.sum(T.sqr(self.W)) + T.sum(T.sqr(self.b))\n",
      "        \n",
      "    def log_likeli(self, y):\n",
      "        return T.mean(y * T.log(self.output) + (1 - y) * T.log(1 - self.output))   \n",
      "           \n",
      "        \n",
      "class HiddenReluLayer(object):\n",
      "    def __init__(self, rng, rng_CUDA, input, n_in, n_out, dropout):\n",
      "        # input and params\n",
      "        self.input = input\n",
      "        self.dropout = dropout\n",
      "        \n",
      "        self.W = theano.shared(value=0.01 * rng.randn(n_in, n_out).astype(tf), name='W', borrow=True)\n",
      "        self.b = theano.shared(value=0.01 * rng.randn(n_out).astype(tf), name='b', borrow=True)\n",
      "        \n",
      "        self.params = [self.W, self.b]\n",
      "        \n",
      "        # AdaGrad\n",
      "        self.hist_grad_W = theano.shared(np.zeros((n_in, n_out), dtype=tf), name='hist_grad_W', borrow=True)\n",
      "        self.hist_grad_b = theano.shared(np.zeros(n_out, dtype=tf), name='hist_grad_b', borrow=True)\n",
      "        \n",
      "        self.hist_grads = [self.hist_grad_W, self.hist_grad_b]\n",
      "        \n",
      "        # output\n",
      "        lin_out = T.dot(self.input, self.W) + self.b\n",
      "        if T.gt(self.dropout, 0):\n",
      "            mask = 1.0 / (1.0 - self.dropout) * T.cast(rng_CUDA.uniform(size=(n_out, )) > self.dropout, dtype=tf)\n",
      "            lin_out = lin_out * mask\n",
      "        self.output = T.maximum(lin_out, 0)\n",
      "        self.L2_sq = T.sum(T.sqr(self.W)) + T.sum(T.sqr(self.b))\n",
      "        \n",
      "    def activation(self, X):\n",
      "        output = T.maximum(T.dot(X, self.W) + self.b, 0)\n",
      "        return output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_units = 1200\n",
      "\n",
      "lam = T.scalar(name='lambda')\n",
      "delta = T.scalar(name='delta')\n",
      "\n",
      "layer0 = HiddenReluLayer(rng, rng_CUDA, input=X_batch, n_in=n_feats, n_out=n_units, dropout=delta)\n",
      "\n",
      "layer1 = HiddenReluLayer(rng, rng_CUDA, input=layer0.output, n_in=n_units, n_out=n_units, dropout=delta)\n",
      "\n",
      "layer2 = HiddenReluLayer(rng, rng_CUDA, input=layer1.output, n_in=n_units, n_out=n_units, dropout=delta)\n",
      "\n",
      "layer3 = LogisticRegressionLayer(rng, input=layer2.output, n_in=n_units, n_out=n_tags)\n",
      "\n",
      "layers = [layer0, layer1, layer2, layer3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = []\n",
      "hist_grads = []\n",
      "\n",
      "for layer in layers:\n",
      "    params += layer.params\n",
      "    hist_grads += layer.hist_grads"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cost = T.neg(layer3.log_likeli(y_batch))\n",
      "for layer in layers:\n",
      "    cost = cost + lam * layer.L2_sq\n",
      "\n",
      "grads = T.grad(cost, params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eta = T.scalar(name='eta')\n",
      "  \n",
      "eps = 1e-8\n",
      "\n",
      "updates = []\n",
      "for param_i, grad_i, hist_grad_i in zip(params, grads, hist_grads):\n",
      "    new_hist_grad_i = hist_grad_i + T.sqr(grad_i)\n",
      "    updates.append((hist_grad_i, new_hist_grad_i))\n",
      "    updates.append((param_i, param_i - eta / (eps + T.sqrt(new_hist_grad_i)) * grad_i))\n",
      "    \n",
      "update_f = theano.function(inputs=[eta, lam, delta], outputs=[layer3.output, cost], updates=updates)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _predict(X, y):\n",
      "    cost = 0\n",
      "    h = X\n",
      "    for layer in layers[:-1]:\n",
      "        h = h.dot(layer.W.get_value()) + layer.b.get_value()\n",
      "        h = np.maximum(h, 0)\n",
      "        cost += lam * (np.sum(layer.W.get_value()**2) + np.sum(layer.b.get_value()**2))\n",
      "    h = h.dot(layers[-1].W.get_value()) + layers[-1].b.get_value()\n",
      "    pred = 1. / (1 + np.exp(-h))\n",
      "    cost += -np.mean(y * np.log(pred) + (1 - y) * np.log(1 - pred))\n",
      "    return pred, cost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cost_train = []\n",
      "cost_test = []\n",
      "acc_train = []\n",
      "acc_test = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eta = .01\n",
      "lam = 0\n",
      "delta = 0.5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nepochs = 30\n",
      "print 'epoch\\tcost.train\\tcost.test\\ttrain.acc\\ttest.acc'\n",
      "sys.stdout.flush()\n",
      "\n",
      "for epoch in xrange(nepochs):\n",
      "    cost_batch = []\n",
      "    acc_batch = []\n",
      "    # Execute stochastic gradient updates\n",
      "    for i in xrange(0, n_samples, batch_size):\n",
      "        inds = np.arange(i, min(i + batch_size, n_samples), dtype=int)\n",
      "        X_batch.set_value(X_train[inds].astype(tf))\n",
      "        y_batch.set_value(y_train[inds].astype(np.int32))\n",
      "        pred, cost = update_f(eta, lam, delta)\n",
      "        cost_batch.append(cost)\n",
      "        acc_batch.append(np.mean((pred > .5) == y_train[inds]))\n",
      "\n",
      "    cost_train.append(np.mean(cost_batch))\n",
      "    acc_train.append(np.mean(acc_batch))\n",
      "    \n",
      "    pred_test, cost = _predict(X_test, y_test)\n",
      "    cost_test.append(cost)\n",
      "    acc_test.append(np.mean((pred_test > .5) == y_test))\n",
      "            \n",
      "    print('%d\\t%.3e\\t%.3e\\t%.3e\\t%.3e' % (epoch, cost_train[-1], cost_test[-1], acc_train[-1], acc_test[-1]))\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch\tcost.train\tcost.test\ttrain.acc\ttest.acc\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\t5.652e-02\t1.373e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\t5.653e-02\t1.373e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\t5.653e-02\t1.371e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\t5.650e-02\t1.372e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\t5.647e-02\t1.371e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5\t5.648e-02\t1.371e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6\t5.646e-02\t1.372e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7\t5.645e-02\t1.371e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8\t5.642e-02\t1.370e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9\t5.643e-02\t1.368e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10\t5.642e-02\t1.369e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11\t5.639e-02\t1.372e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12\t5.639e-02\t1.369e-01\t9.887e-01\t9.553e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13\t5.639e-02\t1.368e-01\t9.887e-01\t9.554e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14\t5.638e-02\t1.364e-01\t9.887e-01\t9.554e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15\t5.634e-02\t1.369e-01\t9.887e-01\t9.554e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "16\t5.631e-02\t1.367e-01\t9.887e-01\t9.554e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "17\t5.633e-02\t1.368e-01\t9.887e-01\t9.554e-01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "18\t5.629e-02\t1.364e-01\t9.887e-01\t9.554e-01\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(acc_train)\n",
      "plt.plot(acc_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "[<matplotlib.lines.Line2D at 0x9730e50>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD9CAYAAACx+XApAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN6D1wM9nOGAAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x9725350>"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute evaluation metrics\n",
      "def construct_pred_mask(tags_predicted, predictat):\n",
      "    n_samples, n_tags = tags_predicted.shape\n",
      "    rankings = np.argsort(-tags_predicted, axis=1)[:, :predictat]\n",
      "    tags_predicted_binary = np.zeros_like(tags_predicted, dtype=bool)\n",
      "    for i in xrange(n_samples):\n",
      "        tags_predicted_binary[i, rankings[i]] = 1\n",
      "    return tags_predicted_binary\n",
      "\n",
      "def per_tag_prec_recall(tags_predicted_binary, tags_true_binary):\n",
      "    mask = np.logical_and(tags_predicted_binary, tags_true_binary)\n",
      "    prec = mask.sum(axis=0) / (tags_predicted_binary.sum(axis=0) + np.spacing(1))\n",
      "    tags_true_count = tags_true_binary.sum(axis=0).astype(float)\n",
      "    idx = (tags_true_count > 0)\n",
      "    recall = mask.sum(axis=0)[idx] / tags_true_count[idx]\n",
      "    return prec, recall\n",
      "\n",
      "\n",
      "def aroc_ap(tags_true_binary, tags_predicted):\n",
      "    n_tags = tags_true_binary.shape[1]\n",
      "    \n",
      "    auc = list()\n",
      "    aprec = list()\n",
      "    for i in xrange(n_tags):\n",
      "        if np.sum(tags_true_binary[:, i]) != 0:\n",
      "            auc.append(roc_auc_score(tags_true_binary[:, i], tags_predicted[:, i]))\n",
      "            aprec.append(average_precision_score(tags_true_binary[:, i], tags_predicted[:, i]))\n",
      "    return auc, aprec\n",
      "\n",
      "\n",
      "def print_out_metrics(tags_true_binary, tags_predicted, predictat):\n",
      "    tags_predicted_binary = construct_pred_mask(tags_predicted, predictat)\n",
      "    prec, recall = per_tag_prec_recall(tags_predicted_binary, tags_true_binary)\n",
      "    mprec, mrecall = np.mean(prec), np.mean(recall)\n",
      "    \n",
      "    print 'Precision = %.3f (%.3f)' % (mprec, np.std(prec) / sqrt(prec.size))\n",
      "    print 'Recall = %.3f (%.3f)' % (mrecall, np.std(recall) / sqrt(recall.size))\n",
      "    print 'F-score = %.3f' % (2 * mprec * mrecall / (mprec + mrecall))\n",
      "\n",
      "    auc, aprec = aroc_ap(tags_true_binary, tags_predicted)\n",
      "    print 'AROC = %.3f (%.3f)' % (np.mean(auc), np.std(auc) / sqrt(len(auc)))\n",
      "    print 'AP = %.3f (%.3f)' % (np.mean(aprec), np.std(aprec) / sqrt(len(aprec)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tags_predicted = pred_test\n",
      "print tags_predicted.min(), tags_predicted.max()\n",
      "\n",
      "div_factor = 1.25\n",
      "tags_predicted = tags_predicted - div_factor * np.mean(tags_predicted, axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5.64468e-11 0.905848\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictat = 20\n",
      "tags_true_binary = (y_test > 0)\n",
      "\n",
      "print_out_metrics(tags_true_binary, tags_predicted, predictat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Precision = 0.192 (0.009)\n",
        "Recall = 0.213 (0.009)\n",
        "F-score = 0.202\n",
        "AROC = 0.791 (0.005)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "AP = 0.184 (0.008)\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}